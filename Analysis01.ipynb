{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis of Amazon Reviews\n",
    "\n",
    "## Project objective\n",
    "\n",
    "To learn and assess the capabilities of using apache pyspark to perform descriptive analysis on large datasets.\n",
    "\n",
    "## Notes\n",
    "\n",
    "These data have been reduced to extract the 5-core, meaning that both the user and item must have at least 5 reviews. Analysis will be performed using an apache pyspark jupyter kernel on a local machine.\n",
    "\n",
    "## References\n",
    "\n",
    "http://spark.apache.org/docs/2.0.1/<br>\n",
    "http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os, re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct data path\n",
    "\n",
    "datapath = os.path.join('..', 'datasets', 'amazon-reviews/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introductory exploration of pyspark\n",
    "\n",
    "Getting familiar with pyspark and spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data into dataframe\n",
    "\n",
    "autodata = spark.read.json(datapath+'reviews_Automotive_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "Row count: 20473\n",
      "Columns: ['asin', 'helpful', 'overall', 'reviewText', 'reviewTime', 'reviewerID', 'reviewerName', 'summary', 'unixReviewTime']\n"
     ]
    }
   ],
   "source": [
    "# some info on the dataframe\n",
    "\n",
    "print('Type:', type(autodata))\n",
    "print('Row count:', autodata.count())\n",
    "print('Columns:', autodata.columns)\n",
    "# print(autodata.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "58\n",
      "Row(asin='B0002NYE5W', helpful=[1, 1], overall=5.0, reviewText=\"Until I went through a detailing class I had never used automobile detailing clay.  Once you have used it, you can never go back.  Not long ago I detailed a new red Audi A5 that sat on the dealer's lot for about 6 months.  The amount of embedded dirt was amazing.\", reviewTime='11 12, 2013', reviewerID='A108AWE1CYYZVB', reviewerName='Good Gora \"Good Gora\"', summary=\"Can't Detail Without It\", unixReviewTime=1384214400)\n"
     ]
    }
   ],
   "source": [
    "# example find reviews that contain audi in the text\n",
    "\n",
    "dfaudi = autodata.filter('LCASE(reviewText) RLIKE \"audi(?![obetn])\"')\n",
    "print(type(dfaudi))\n",
    "print(dfaudi.count())\n",
    "print(dfaudi.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20473, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20473 entries, 0 to 20472\n",
      "Data columns (total 9 columns):\n",
      "asin              20473 non-null object\n",
      "helpful           20473 non-null object\n",
      "overall           20473 non-null float64\n",
      "reviewText        20473 non-null object\n",
      "reviewTime        20473 non-null object\n",
      "reviewerID        20473 non-null object\n",
      "reviewerName      20260 non-null object\n",
      "summary           20473 non-null object\n",
      "unixReviewTime    20473 non-null int64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert pyspark dataframe to pandas dataframe if its small enough to fit in memory\n",
    "\n",
    "rowcount = autodata.count()\n",
    "colcount = len(autodata.columns)\n",
    "\n",
    "if rowcount < 100000 and colcount < 100:\n",
    "    df = pd.DataFrame(autodata.collect(), columns=autodata.columns)\n",
    "    print(df.shape)\n",
    "    print(df.info())\n",
    "else:\n",
    "    print('Dataset too large to convert to pandas dataframe.')\n",
    "    print('Rows:', str(rowcount), '\\t', 'Columns:', str(colcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I needed a set of jumper cables for my new car...</td>\n",
       "      <td>08 17, 2011</td>\n",
       "      <td>A3F73SC1LY51OO</td>\n",
       "      <td>Alan Montgomery</td>\n",
       "      <td>Work Well - Should Have Bought Longer Ones</td>\n",
       "      <td>1313539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>These long cables work fine for my truck, but ...</td>\n",
       "      <td>09 4, 2011</td>\n",
       "      <td>A20S66SKYXULG2</td>\n",
       "      <td>alphonse</td>\n",
       "      <td>Okay long cables</td>\n",
       "      <td>1315094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Can't comment much on these since they have no...</td>\n",
       "      <td>07 25, 2013</td>\n",
       "      <td>A2I8LFSN2IS5EO</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Looks and feels heavy Duty</td>\n",
       "      <td>1374710400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[19, 19]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
       "      <td>12 21, 2010</td>\n",
       "      <td>A3GT2EWQSO45ZG</td>\n",
       "      <td>DeusEx</td>\n",
       "      <td>Excellent choice for Jumper Cables!!!</td>\n",
       "      <td>1292889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I purchased the 12' feet long cable set and th...</td>\n",
       "      <td>07 4, 2012</td>\n",
       "      <td>A3ESWJPAVRPWB4</td>\n",
       "      <td>E. Hernandez</td>\n",
       "      <td>Excellent, High Quality Starter Cables</td>\n",
       "      <td>1341360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These Jumper cables are heavy Duty, Yet easy t...</td>\n",
       "      <td>11 14, 2009</td>\n",
       "      <td>A1ORODEBRN64C</td>\n",
       "      <td>James F. Magowan \"Jimmy Mac\"</td>\n",
       "      <td>Compact and Strong !</td>\n",
       "      <td>1258156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bought these for my k2500 suburban plenty of l...</td>\n",
       "      <td>01 10, 2012</td>\n",
       "      <td>A2R49ZN3G6FTCQ</td>\n",
       "      <td>John M. Harrell</td>\n",
       "      <td>nice cables</td>\n",
       "      <td>1326153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>these are good enough to get most motorized ve...</td>\n",
       "      <td>06 13, 2013</td>\n",
       "      <td>A1Q65KYDKXIX8E</td>\n",
       "      <td>Leeland H.</td>\n",
       "      <td>for cars and pickups</td>\n",
       "      <td>1371081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Coleman Cable 08665 12-Feet Heavy-Duty Tru...</td>\n",
       "      <td>07 18, 2013</td>\n",
       "      <td>A3BI8BKIHESDNQ</td>\n",
       "      <td>L. J. Cunningham</td>\n",
       "      <td>Coleman Cable 08665 12-Feet Heavy-Duty Truck a...</td>\n",
       "      <td>1374105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00002243X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have an old car, Its bound to need these som...</td>\n",
       "      <td>01 22, 2014</td>\n",
       "      <td>A1R089P5AS26UE</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Beefy</td>\n",
       "      <td>1390348800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin   helpful  overall  \\\n",
       "0  B00002243X    [4, 4]      5.0   \n",
       "1  B00002243X    [1, 1]      4.0   \n",
       "2  B00002243X    [0, 0]      5.0   \n",
       "3  B00002243X  [19, 19]      5.0   \n",
       "4  B00002243X    [0, 0]      5.0   \n",
       "5  B00002243X    [1, 1]      5.0   \n",
       "6  B00002243X    [1, 1]      5.0   \n",
       "7  B00002243X    [0, 0]      5.0   \n",
       "8  B00002243X    [0, 0]      4.0   \n",
       "9  B00002243X    [0, 0]      5.0   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I needed a set of jumper cables for my new car...  08 17, 2011   \n",
       "1  These long cables work fine for my truck, but ...   09 4, 2011   \n",
       "2  Can't comment much on these since they have no...  07 25, 2013   \n",
       "3  I absolutley love Amazon!!!  For the price of ...  12 21, 2010   \n",
       "4  I purchased the 12' feet long cable set and th...   07 4, 2012   \n",
       "5  These Jumper cables are heavy Duty, Yet easy t...  11 14, 2009   \n",
       "6  bought these for my k2500 suburban plenty of l...  01 10, 2012   \n",
       "7  these are good enough to get most motorized ve...  06 13, 2013   \n",
       "8  The Coleman Cable 08665 12-Feet Heavy-Duty Tru...  07 18, 2013   \n",
       "9  I have an old car, Its bound to need these som...  01 22, 2014   \n",
       "\n",
       "       reviewerID                  reviewerName  \\\n",
       "0  A3F73SC1LY51OO               Alan Montgomery   \n",
       "1  A20S66SKYXULG2                      alphonse   \n",
       "2  A2I8LFSN2IS5EO                         Chris   \n",
       "3  A3GT2EWQSO45ZG                        DeusEx   \n",
       "4  A3ESWJPAVRPWB4                  E. Hernandez   \n",
       "5   A1ORODEBRN64C  James F. Magowan \"Jimmy Mac\"   \n",
       "6  A2R49ZN3G6FTCQ               John M. Harrell   \n",
       "7  A1Q65KYDKXIX8E                    Leeland H.   \n",
       "8  A3BI8BKIHESDNQ              L. J. Cunningham   \n",
       "9  A1R089P5AS26UE                          Mike   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0         Work Well - Should Have Bought Longer Ones      1313539200  \n",
       "1                                   Okay long cables      1315094400  \n",
       "2                         Looks and feels heavy Duty      1374710400  \n",
       "3              Excellent choice for Jumper Cables!!!      1292889600  \n",
       "4             Excellent, High Quality Starter Cables      1341360000  \n",
       "5                               Compact and Strong !      1258156800  \n",
       "6                                        nice cables      1326153600  \n",
       "7                               for cars and pickups      1371081600  \n",
       "8  Coleman Cable 08665 12-Feet Heavy-Duty Truck a...      1374105600  \n",
       "9                                              Beefy      1390348800  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Machine learning with Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='Work Well - Should Have Bought Longer Ones', overall=5.0, helps=4, votes=4),\n",
       " Row(summary='Okay long cables', overall=4.0, helps=1, votes=1),\n",
       " Row(summary='Looks and feels heavy Duty', overall=5.0, helps=0, votes=0),\n",
       " Row(summary='Excellent choice for Jumper Cables!!!', overall=5.0, helps=19, votes=19),\n",
       " Row(summary='Excellent, High Quality Starter Cables', overall=5.0, helps=0, votes=0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# begin by converting helpfulness of reviews to something useful\n",
    "# create column for number of helpful votes and another for number of votes\n",
    "\n",
    "udf0 = UserDefinedFunction(lambda x: x[0], IntegerType())\n",
    "udf1 = UserDefinedFunction(lambda x: x[1], IntegerType())\n",
    "\n",
    "keepcols = [\"helpful\", \"summary\", \"overall\"]\n",
    "\n",
    "helpvotedata = autodata.select(*keepcols).withColumn(\"helps\", udf0(\"helpful\")).withColumn(\"votes\", udf1(\"helpful\")).\\\n",
    "                drop(\"helpful\")\n",
    "helpvotedata.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Natural language processing with Spark MLlib\n",
    "\n",
    "Convert summary text into features that would be appropriate for a machine learning model.\n",
    "\n",
    "## Reference\n",
    "http://spark.apache.org/docs/latest/ml-features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row(features=SparseVector(64, {23: 3.3758, 27: 2.9896, 39: 3.0864, 45: 2.7952, 52: 1.7119, 63: 2.863}), summary='Work Well - Should Have Bought Longer Ones', words=['work', 'well', '-', 'bought', 'longer', 'ones'])\n",
      "\n",
      "Row(features=SparseVector(64, {19: 3.6243, 40: 3.1735, 42: 3.2831}), summary='Okay long cables', words=['okay', 'long', 'cables'])\n",
      "\n",
      "Row(features=SparseVector(64, {30: 3.478, 37: 2.804, 49: 5.176}), summary='Looks and feels heavy Duty', words=['looks', 'feels', 'heavy', 'duty'])\n",
      "\n",
      "Row(features=SparseVector(64, {9: 3.2031, 30: 3.478, 35: 3.3407, 41: 3.0424}), summary='Excellent choice for Jumper Cables!!!', words=['excellent', 'choice', 'jumper', 'cables!!!'])\n",
      "\n",
      "Row(features=SparseVector(64, {19: 3.6243, 20: 3.0993, 38: 3.1069, 49: 2.588, 54: 3.396}), summary='Excellent, High Quality Starter Cables', words=['excellent,', 'high', 'quality', 'starter', 'cables'])\n",
      "\n",
      "Row(features=SparseVector(64, {8: 3.1312, 31: 2.9694, 62: 3.2115}), summary='Compact and Strong !', words=['compact', 'strong', '!'])\n",
      "\n",
      "Row(features=SparseVector(64, {10: 2.6978, 19: 3.6243}), summary='nice cables', words=['nice', 'cables'])\n",
      "\n",
      "Row(features=SparseVector(64, {35: 3.3407, 42: 3.2831}), summary='for cars and pickups', words=['cars', 'pickups'])\n",
      "\n",
      "Row(features=SparseVector(64, {0: 3.6712, 8: 3.1312, 10: 2.6978, 13: 2.9121, 29: 2.9984, 34: 3.147, 36: 3.0242, 42: 3.2831, 62: 3.2115}), summary='Coleman Cable 08665 12-Feet Heavy-Duty Truck and Auto Battery Booster', words=['coleman', 'cable', '08665', '12-feet', 'heavy-duty', 'truck', 'auto', 'battery', 'booster'])\n",
      "\n",
      "Row(features=SparseVector(64, {30: 3.478}), summary='Beefy', words=['beefy'])\n"
     ]
    }
   ],
   "source": [
    "# tokenize text with bag of words approach and create new column\n",
    "tokenizer = Tokenizer(inputCol=\"summary\", outputCol=\"rawWords\")\n",
    "rawwordsData = tokenizer.transform(autodata)\n",
    "\n",
    "# apply stopwords remover\n",
    "remover = StopWordsRemover(inputCol=\"rawWords\", outputCol=\"words\")\n",
    "wordsData = remover.transform(rawwordsData)\n",
    "\n",
    "# hash words with given number of bins (numFeatures)\n",
    "# term frequencies are calculated based on mapping indices\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=64)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "# IDF is an estimator that is fit on a dataset and returns a model\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "# examine first 3 rows\n",
    "for features_label in rescaledData.select(\"features\", \"summary\", \"words\").take(10):\n",
    "    print()\n",
    "    print(features_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# sentenceData = spark.createDataFrame([\n",
    "#     (0, [\"I\", \"saw\", \"the\", \"red\", \"balloon\"]),\n",
    "#     (1, [\"Mary\", \"had\", \"a\", \"little\", \"lamb\"])\n",
    "# ], [\"id\", \"raw\"])\n",
    "\n",
    "# remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")\n",
    "# remover.transform(sentenceData).show(truncate=False)\n",
    "\n",
    "print(StopWordsRemover.loadDefaultStopWords(\"english\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
